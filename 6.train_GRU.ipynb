{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "beb6bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.spatial import distance\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d59ceb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "468036e1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 랜드마크 인덱스 정의 # 11개\n",
    "LANDMARKS = [0, 11, 12, 15, 16, 23, 24, 25, 26, 27, 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ec35a6a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# # 데이터 증강 함수 정의\n",
    "# def augment_sequence(sequence, factor=0.2):\n",
    "#     time_warped = []\n",
    "#     for landmark in sequence:\n",
    "#         x = np.arange(len(landmark))\n",
    "#         f = interp1d(x, landmark, kind='linear', axis=0)\n",
    "#         x_new = np.linspace(0, len(landmark) - 1, num=int(len(landmark) * (1 + factor)))\n",
    "#         time_warped.append(f(x_new))\n",
    "#     return np.array(time_warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "18debf6c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 바운딩 박스 비율 클래스 정의 함수\n",
    "def bbox_ratio_class(ratio):\n",
    "    if ratio < 0.7:\n",
    "        return 0  # Normal 가능성 높은 class\n",
    "    else:\n",
    "        return 1  # Danger or Fall 가능성 높은 class\n",
    "\n",
    "# YOLO xy 비율 계산 함수\n",
    "def calculate_yolo_xy_ratio(frame):\n",
    "    bbox = frame.get('bbox', None)\n",
    "    if bbox and (bbox['x2'] - bbox['x1']) != 0:\n",
    "        yolo_xy_ratio = round((bbox['y2'] - bbox['y1']) / (bbox['x2'] - bbox['x1']), 3)\n",
    "    else:\n",
    "        yolo_xy_ratio = 0.0\n",
    "    return yolo_xy_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ea132622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 머리 및 상체 속도 계산 함수 (시퀀스 평균값 사용)\n",
    "def calculate_head_upper_body_speed(sequence):\n",
    "    speeds = []\n",
    "    for j in range(1, len(sequence)):\n",
    "        keypoints = sequence[j]\n",
    "        prev_keypoints = sequence[j - 1]\n",
    "        h = np.array([keypoints.get(f'landmark_0', {}).get('x', 0.0), keypoints.get(f'landmark_0', {}).get('y', 0.0)])\n",
    "        l = np.array([keypoints.get(f'landmark_11', {}).get('x', 0.0), keypoints.get(f'landmark_11', {}).get('y', 0.0)])\n",
    "        r = np.array([keypoints.get(f'landmark_12', {}).get('x', 0.0), keypoints.get(f'landmark_12', {}).get('y', 0.0)])\n",
    "\n",
    "        # 이전 프레임의 좌표\n",
    "        prev_h = np.array([prev_keypoints.get(f'landmark_0', {}).get('x', 0.0), prev_keypoints.get(f'landmark_0', {}).get('y', 0.0)])\n",
    "        prev_l = np.array([prev_keypoints.get(f'landmark_11', {}).get('x', 0.0), prev_keypoints.get(f'landmark_11', {}).get('y', 0.0)])\n",
    "        prev_r = np.array([prev_keypoints.get(f'landmark_12', {}).get('x', 0.0), prev_keypoints.get(f'landmark_12', {}).get('y', 0.0)])\n",
    "\n",
    "        # 현재 프레임과 이전 프레임의 상체 중심\n",
    "        center_new = (h + l + r) / 3\n",
    "        center_prev = (prev_h + prev_l + prev_r) / 3\n",
    "\n",
    "        # 유클리드 거리 계산 (6프레임당 일정하므로 속력이라 봐도 무방함)\n",
    "        dist_new = distance.euclidean(center_new, center_prev)\n",
    "        speeds.append(dist_new)\n",
    "\n",
    "    # 평균 속력 계산\n",
    "    if speeds:\n",
    "        return sum(speeds) / len(speeds)\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "594bd98f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "# 현재 input은 mediapipe의 관절 좌표값 22개 + YOLO xy ratio + bbox_ratio_class + 머리/상체 속도 => 25개\n",
    "class FallSequenceDataset(Dataset):\n",
    "    def __init__(self, json_files, sequence_length=3, input_config='full'):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.sequences = []\n",
    "        self.labels = []\n",
    "        self.scaler = StandardScaler()\n",
    "        self.input_config = input_config\n",
    "\n",
    "        all_landmarks = []\n",
    "\n",
    "        for json_file in tqdm(json_files, desc=\"Processing JSON files\"):\n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            frames = list(data['pose_data'].values())\n",
    "\n",
    "            for i in range(0, len(frames) - self.sequence_length + 1, self.sequence_length):\n",
    "                sequence = frames[i:i + self.sequence_length]\n",
    "                landmarks = []\n",
    "\n",
    "                # YOLO xy ratio 및 바운딩 박스 클래스는 시퀀스마다 1개씩만 추가\n",
    "                yolo_xy_ratio = calculate_yolo_xy_ratio(sequence[-1])  # 마지막 프레임 기준으로 계산\n",
    "                ratio_class = bbox_ratio_class(yolo_xy_ratio)\n",
    "                head_torso_speed = calculate_head_upper_body_speed(sequence)\n",
    "\n",
    "                for j, frame in enumerate(sequence):\n",
    "                    frame_landmarks = []\n",
    "                    if frame is not None:\n",
    "                        if self.input_config in ['full', 'mediapipe']:\n",
    "                            for landmark in LANDMARKS:\n",
    "                                landmark_data = frame.get(f'landmark_{landmark}', None)\n",
    "                                if landmark_data:\n",
    "                                    frame_landmarks.extend([\n",
    "                                        round(landmark_data['x'], 3),  # 소수점 세 자리로 반올림\n",
    "                                        round(landmark_data['y'], 3)\n",
    "                                    ])\n",
    "                                else:\n",
    "                                    frame_landmarks.extend([0.0, 0.0])\n",
    "\n",
    "                        if self.input_config in ['full', 'simplified']:\n",
    "                            # YOLO xy ratio, 바운딩 박스 클래스, 머리/상체 속도 추가 (시퀀스 단위로 동일 값 사용)\n",
    "                            frame_landmarks.append(yolo_xy_ratio)\n",
    "                            frame_landmarks.append(ratio_class)\n",
    "                            frame_landmarks.append(head_torso_speed)\n",
    "                    \n",
    "                    landmarks.append(frame_landmarks)\n",
    "\n",
    "                # 데이터 증강 없이 원래 데이터를 사용\n",
    "                all_landmarks.extend(landmarks)\n",
    "\n",
    "                # 레이블 재정의\n",
    "                if sequence[-1]['class'] == 'Normal':\n",
    "                    label = 0  # 비낙상\n",
    "                elif sequence[-1]['class'] == 'Danger':\n",
    "                    label = 1  # 낙상 위험\n",
    "                elif sequence[-1]['class'] == 'Fall':\n",
    "                    label = 2  # 완전 낙상\n",
    "\n",
    "                self.sequences.append(landmarks)\n",
    "                self.labels.append(label)\n",
    "\n",
    "        # 전체 데이터 정규화\n",
    "        all_landmarks = np.array(all_landmarks)\n",
    "        all_landmarks_scaled = self.scaler.fit_transform(all_landmarks)\n",
    "\n",
    "        # 정규화된 데이터를 다시 시퀀스로 재구성\n",
    "        for i in range(len(self.sequences)):\n",
    "            start = i * self.sequence_length\n",
    "            end = start + self.sequence_length\n",
    "            self.sequences[i] = all_landmarks_scaled[start:end]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.sequences[idx]), torch.LongTensor([self.labels[idx]]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ddba071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU 기반 낙상 감지 모델 정의\n",
    "class FallDetectionGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, num_layers=2, num_classes=3):\n",
    "        super(FallDetectionGRU, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(2, x.size(0), 128).to(x.device)  # 초기 은닉 상태 정의\n",
    "        out, _ = self.gru(x, h_0)\n",
    "        out = self.fc(out[:, -1, :])  # 마지막 time step의 출력을 사용\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c562b8d5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON files: 100%|██████████| 1935/1935 [00:07<00:00, 268.58it/s]\n",
      "Processing JSON files: 100%|██████████| 386/386 [00:01<00:00, 271.68it/s]\n",
      "Processing JSON files: 100%|██████████| 397/397 [00:01<00:00, 260.89it/s]\n",
      "Processing JSON files: 100%|██████████| 1935/1935 [00:05<00:00, 368.45it/s]\n",
      "Processing JSON files: 100%|██████████| 386/386 [00:01<00:00, 350.06it/s]\n",
      "Processing JSON files: 100%|██████████| 397/397 [00:00<00:00, 416.14it/s]\n",
      "Processing JSON files: 100%|██████████| 1935/1935 [00:06<00:00, 285.64it/s]\n",
      "Processing JSON files: 100%|██████████| 386/386 [00:01<00:00, 302.98it/s]\n",
      "Processing JSON files: 100%|██████████| 397/397 [00:01<00:00, 271.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# 검증 및 테스트 데이터셋 로드 경로\n",
    "train_json_folder = r'D:\\Falldown\\Dataset\\Video_Dataset\\Json_combined\\Train'\n",
    "valid_json_folder = r'D:\\Falldown\\Dataset\\Video_Dataset\\Json_combined\\Val'\n",
    "test_json_folder = r'D:\\Falldown\\Dataset\\Video_Dataset\\Json_combined\\Test'\n",
    "\n",
    "# 각 데이터 폴더에서 JSON 파일 목록 생성\n",
    "train_json_files = [os.path.join(train_json_folder, f) for f in os.listdir(train_json_folder) if f.endswith('.json')]\n",
    "valid_json_files = [os.path.join(valid_json_folder, f) for f in os.listdir(valid_json_folder) if f.endswith('.json')]\n",
    "test_json_files = [os.path.join(test_json_folder, f) for f in os.listdir(test_json_folder) if f.endswith('.json')]\n",
    "\n",
    "# 데이터셋 생성 (입력 데이터 설정에 따라)\n",
    "train_full_dataset = FallSequenceDataset(train_json_files, input_config='full')\n",
    "valid_full_dataset = FallSequenceDataset(valid_json_files, input_config='full')\n",
    "test_full_dataset = FallSequenceDataset(test_json_files, input_config='full')\n",
    "\n",
    "train_simplified_dataset = FallSequenceDataset(train_json_files, input_config='simplified')\n",
    "valid_simplified_dataset = FallSequenceDataset(valid_json_files, input_config='simplified')\n",
    "test_simplified_dataset = FallSequenceDataset(test_json_files, input_config='simplified')\n",
    "\n",
    "train_mediapipe_dataset = FallSequenceDataset(train_json_files, input_config='mediapipe')\n",
    "valid_mediapipe_dataset = FallSequenceDataset(valid_json_files, input_config='mediapipe')\n",
    "test_mediapipe_dataset = FallSequenceDataset(test_json_files, input_config='mediapipe')\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader_full = DataLoader(train_full_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader_full = DataLoader(valid_full_dataset, batch_size=32, shuffle=False)\n",
    "test_loader_full = DataLoader(test_full_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "train_loader_simplified = DataLoader(train_simplified_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader_simplified = DataLoader(valid_simplified_dataset, batch_size=32, shuffle=False)\n",
    "test_loader_simplified = DataLoader(test_simplified_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "train_loader_mediapipe = DataLoader(train_mediapipe_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader_mediapipe = DataLoader(valid_mediapipe_dataset, batch_size=32, shuffle=False)\n",
    "test_loader_mediapipe = DataLoader(test_mediapipe_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fe890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 가중치 계산 및 손실 함수 정의 (훈련 데이터셋 기준)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_full_dataset.labels), y=train_full_dataset.labels)\n",
    "class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# 모델 준비\n",
    "def create_model_for_dataset(dataset):\n",
    "    if len(dataset) > 0:\n",
    "        sample_sequence, sample_label = dataset[0]\n",
    "        input_size = len(sample_sequence[0])  # 시퀀스 내의 각 프레임에서 입력의 길이를 가져옴\n",
    "        return FallDetectionGRU(input_size).to(device)\n",
    "    else:\n",
    "        print(\"데이터 없음\")\n",
    "        exit()\n",
    "\n",
    "# 학습 파라미터 설정\n",
    "num_epochs = 500\n",
    "best_loss = float('inf')\n",
    "patience = 50\n",
    "no_improve = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c39017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 루프\n",
    "for train_loader, valid_loader, model_name, dataset, lr in [\n",
    "    (train_loader_full, valid_loader_full, 'best_fall_detection_gru_001_full.pt', train_full_dataset, 0.001),\n",
    "    (train_loader_full, valid_loader_full, 'best_fall_detection_gru_0001_full.pt', train_full_dataset, 0.0001),\n",
    "    (train_loader_simplified, valid_loader_simplified, 'best_fall_detection_gru_0001_simplified.pt', train_simplified_dataset, 0.0001),\n",
    "    (train_loader_mediapipe, valid_loader_mediapipe, 'best_fall_detection_gru_0001_mediapipe.pt', train_mediapipe_dataset, 0.0001)\n",
    "]:\n",
    "    # 모델을 새로 생성\n",
    "    model = create_model_for_dataset(dataset)\n",
    "    model.to(device)\n",
    "\n",
    "    # 옵티마이저와 스케줄러 설정\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "    # 각 학습 설정별 초기화\n",
    "    best_loss = float('inf')\n",
    "    no_improve = 0\n",
    "    \n",
    "    print(f\"{model_name} 학습 시작\", flush=True)\n",
    "    print(\"\\n\" + \"=\" * 20 + f\" Training Configuration: GRU with input_config='{train_loader.dataset.input_config}' and lr='{optimizer.param_groups[0]['lr']}' \" + \"=\" * 20 + \"\\n\")\n",
    "\n",
    "    # 입력 크기 체크 (훈련 시작 시 1회만 출력)\n",
    "    sequences, labels = next(iter(train_loader))\n",
    "    print(f'현재 입력 크기 (마지막 차원): {sequences.size(-1)}')\n",
    "    print(f'예상 입력 크기: {model.gru.input_size}')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss_train = 0\n",
    "\n",
    "        for sequences, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences)\n",
    "            loss_train = criterion(outputs, labels.view(-1))\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss_train += loss_train.item()\n",
    "\n",
    "        avg_loss_train = total_loss_train / len(train_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_loss_train:.4f}')\n",
    "\n",
    "        # 검증 데이터셋 평가\n",
    "        model.eval()\n",
    "        total_loss_valid = 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in valid_loader:\n",
    "                sequences, labels = sequences.to(device), labels.to(device)\n",
    "                outputs = model(sequences)\n",
    "                loss_valid = criterion(outputs, labels.view(-1))\n",
    "                total_loss_valid += loss_valid.item()\n",
    "\n",
    "        avg_loss_valid = total_loss_valid / len(valid_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Valid Loss: {avg_loss_valid:.4f}')\n",
    "\n",
    "        # 학습률 조정 스케줄러 업데이트\n",
    "        scheduler.step(avg_loss_valid)\n",
    "\n",
    "        # 최상의 모델 저장\n",
    "        if avg_loss_valid < best_loss:\n",
    "            best_loss = avg_loss_valid\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), model_name)\n",
    "        else:\n",
    "            no_improve += 1\n",
    "\n",
    "        if no_improve >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 지표 계산 함수 정의\n",
    "def calculate_metrics(model, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in data_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            outputs = model(sequences)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    return f1, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c64456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습이 완료된 후 검증 및 테스트 데이터셋에 대한 성능 평가\n",
    "for test_loader, model in [\n",
    "    (test_loader_full, model_full),\n",
    "    (test_loader_simplified, model_simplified),\n",
    "    (test_loader_mediapipe, model_mediapipe)\n",
    "]:\n",
    "    test_f1, test_cm = calculate_metrics(model, test_loader)\n",
    "    print(f'Test F1: {test_f1:.4f}')\n",
    "    print(f'Test CM:\\n{test_cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df25d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CNN 기반 낙상 감지 모델 정의\n",
    "# class FallDetectionCNN(nn.Module):\n",
    "#     def __init__(self, input_size, num_classes=3):\n",
    "#         super(FallDetectionCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "#         self.fc1 = nn.Linear(128 * input_size, 256)\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "#         self.fc3 = nn.Linear(128, num_classes)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.unsqueeze(1)  # Conv1d expects (batch_size, channels, length), adding channel dimension\n",
    "#         x = torch.relu(self.conv1(x))\n",
    "#         x = torch.relu(self.conv2(x))\n",
    "#         x = torch.relu(self.conv3(x))\n",
    "#         x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
