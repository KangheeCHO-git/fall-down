{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "from torch.nn.functional import softmax\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**### 올바른 json을 input으로 넣었는지 Visualization 수행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  12%|█▎        | 1/8 [00:23<02:47, 23.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 00028_H_A_FY_C1, output saved to D:\\Falldown\\code-git\\Visualized_Video_Json\\00028_H_A_FY_C1_visualized.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  25%|██▌       | 2/8 [00:48<02:25, 24.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 00130_H_A_FY_C2, output saved to D:\\Falldown\\code-git\\Visualized_Video_Json\\00130_H_A_FY_C2_visualized.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  38%|███▊      | 3/8 [00:49<01:07, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 00175_H_A_BY_C3, output saved to D:\\Falldown\\code-git\\Visualized_Video_Json\\00175_H_A_BY_C3_visualized.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  50%|█████     | 4/8 [01:11<01:08, 17.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 00712_H_D_BY_C4, output saved to D:\\Falldown\\code-git\\Visualized_Video_Json\\00712_H_D_BY_C4_visualized.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  62%|██████▎   | 5/8 [01:34<00:56, 18.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 01757_Y_E_SY_C5, output saved to D:\\Falldown\\code-git\\Visualized_Video_Json\\01757_Y_E_SY_C5_visualized.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  75%|███████▌  | 6/8 [01:55<00:39, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 01931_Y_A_SY_C6, output saved to D:\\Falldown\\code-git\\Visualized_Video_Json\\01931_Y_A_SY_C6_visualized.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  88%|████████▊ | 7/8 [01:56<00:13, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 01224_O_E_N_C7, output saved to D:\\Falldown\\code-git\\Visualized_Video_Json\\01224_O_E_N_C7_visualized.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 8/8 [01:56<00:00, 14.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 01251_O_E_N_C8, output saved to D:\\Falldown\\code-git\\Visualized_Video_Json\\01251_O_E_N_C8_visualized.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# JSON 및 비디오 경로 설정\n",
    "json_dir = r\"D:\\Falldown\\Dataset\\Video_Dataset\\Json_combined\\Test\"\n",
    "original_video_dir = r\"D:\\Falldown\\Dataset\\Video_Dataset\\Video\\Test\"\n",
    "output_dir = r\"D:\\Falldown\\code-git\\Visualized_Video_Json\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 파일명 리스트\n",
    "filenames = [\n",
    "    \"00028_H_A_FY_C1\",\n",
    "    \"00130_H_A_FY_C2\",\n",
    "    \"00175_H_A_BY_C3\",\n",
    "    \"00712_H_D_BY_C4\",\n",
    "    \"01757_Y_E_SY_C5\",\n",
    "    \"01931_Y_A_SY_C6\",\n",
    "    \"01224_O_E_N_C7\",\n",
    "    \"01251_O_E_N_C8\"\n",
    "]\n",
    "\n",
    "# 시각화를 위한 함수\n",
    "def visualize_results(frame, bbox, results_pose, label_text, target_size, original_width, original_height):\n",
    "    if not bbox and not results_pose: # 데이터가 없으면 시각화 작업 없이 바로 반환\n",
    "        return frame\n",
    "    \n",
    "    color_map = {\n",
    "        'Normal': (0, 255, 0),      # Normal: 초록색\n",
    "        'Danger': (0, 165, 255),    # Danger: 주황색\n",
    "        'Fall': (0, 0, 255)         # Fall: 빨간색\n",
    "    }\n",
    "    color = color_map.get(label_text, (255, 255, 255))  # 기본값은 흰색\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    scale = min(target_size[0] / w, target_size[1] / h)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    pad_w, pad_h = (target_size[0] - new_w) // 2, (target_size[1] - new_h) // 2\n",
    "\n",
    "    # Yolo bbox 시각화\n",
    "    for adjusted_bbox in bbox:\n",
    "        x1, y1, x2, y2 = adjusted_bbox\n",
    "        # 640x640으로 resize와 padding 된 yolo 좌표를 원본 동영상 좌표로 복구\n",
    "        original_x1 = (x1 - pad_w) * (original_width / new_w)\n",
    "        original_y1 = (y1 - pad_h) * (original_height / new_h)\n",
    "        original_x2 = (x2 - pad_w) * (original_width / new_w)\n",
    "        original_y2 = (y2 - pad_h) * (original_height / new_h)\n",
    "\n",
    "        label = f\"Class: {label_text}\"\n",
    "        cv2.rectangle(frame, (int(original_x1), int(original_y1)), (int(original_x2), int(original_y2)), color, thickness=3)\n",
    "        cv2.putText(frame, label, (int(original_x1), int(original_y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, thickness=2)\n",
    "\n",
    "    # Mediapipe 관절 좌표 시각화\n",
    "    for landmark in results_pose:\n",
    "        global_x = landmark[0]\n",
    "        global_y = landmark[1]\n",
    "        # 640x640으로 resize와 padding 된 landmark 좌표를 원본 동영상 좌표로 복구\n",
    "        original_landmark_x = (global_x - pad_w) * (original_width / new_w)\n",
    "        original_landmark_y = (global_y - pad_h) * (original_height / new_h)\n",
    "\n",
    "        cv2.circle(frame, (int(original_landmark_x), int(original_landmark_y)), radius=3, color=(0, 255, 255), thickness=-1)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# JSON 파일과 비디오 처리\n",
    "for filename in tqdm(filenames, desc=\"Processing files\"):\n",
    "    json_path = os.path.join(json_dir, filename + \".json\")\n",
    "    video_path = os.path.join(original_video_dir, filename + \".mp4\")\n",
    "    output_path = os.path.join(output_dir, filename + \"_visualized.mp4\")\n",
    "    target_size = (640, 640)\n",
    "\n",
    "    # JSON 로드\n",
    "    with open(json_path, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    # 비디오 로드\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # 비디오 저장 설정\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (original_width, original_height))\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # 6 프레임마다 처리\n",
    "        frame_key = f\"frame_{frame_idx}\"\n",
    "        if frame_idx % 6 == 0 and frame_key in json_data[\"pose_data\"]:\n",
    "            frame_data = json_data[\"pose_data\"][frame_key]\n",
    "\n",
    "            # bbox 데이터 가져오기\n",
    "            bbox_data = frame_data.get(\"bbox\", {})\n",
    "            bbox = []\n",
    "            if isinstance(bbox_data, dict):  # bbox_data가 딕셔너리일 때만 처리\n",
    "                bbox = [[\n",
    "                    bbox_data.get(\"x1\", 0),\n",
    "                    bbox_data.get(\"y1\", 0),\n",
    "                    bbox_data.get(\"x2\", 0),\n",
    "                    bbox_data.get(\"y2\", 0)\n",
    "                ]]\n",
    "\n",
    "            # landmarks 데이터 가져오기\n",
    "            results_pose = [\n",
    "                (landmark_data[\"x\"] * target_size[0], landmark_data[\"y\"] * target_size[1])\n",
    "                for key, landmark_data in frame_data.items()\n",
    "                if key.startswith(\"landmark_\") and \"x\" in landmark_data and \"y\" in landmark_data\n",
    "            ]\n",
    "            \n",
    "            label_text = frame_data.get(\"class\", \"Unknown\") # class 데이터 가져오기\n",
    "\n",
    "            # 시각화 수행\n",
    "            frame = visualize_results(frame, bbox, results_pose, label_text, target_size,\n",
    "                                      original_width, original_height)\n",
    "\n",
    "        out.write(frame)\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Processed {filename}, output saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
