{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe==0.10.11 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.10.11)\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mediapipe==0.10.11) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mediapipe==0.10.11) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mediapipe==0.10.11) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mediapipe==0.10.11) (0.4.34)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mediapipe==0.10.11) (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mediapipe==0.10.11) (1.26.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mediapipe==0.10.11) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mediapipe==0.10.11) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mediapipe==0.10.11) (0.5.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sounddevice>=0.4.4->mediapipe==0.10.11) (1.17.1)\n",
      "Requirement already satisfied: jaxlib<=0.4.34,>=0.4.34 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jax->mediapipe==0.10.11) (0.4.34)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jax->mediapipe==0.10.11) (0.5.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jax->mediapipe==0.10.11) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jax->mediapipe==0.10.11) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->mediapipe==0.10.11) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->mediapipe==0.10.11) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->mediapipe==0.10.11) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->mediapipe==0.10.11) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->mediapipe==0.10.11) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->mediapipe==0.10.11) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->mediapipe==0.10.11) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->mediapipe==0.10.11) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.11) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.11) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mediapipe==0.10.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (8.3.11)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (1.26.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (2.4.1+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (0.19.1+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (2.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (2024.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "import glob\n",
    "import time\n",
    "import tracemalloc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import Image, clear_output\n",
    "from torch.cuda import memory_allocated, empty_cache\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\project\\New_Data\\Image\n",
      "67840\n",
      "67840 67840\n"
     ]
    }
   ],
   "source": [
    "data_root = r'E:\\project\\New_Data'\n",
    "file_root = rf'{data_root}\\Image'\n",
    "project_name = 'fall_detection'\n",
    "print(file_root)\n",
    "train_root = rf'{data_root}\\train'\n",
    "valid_root = rf'{data_root}\\valid'\n",
    "test_root = rf'{data_root}\\test'\n",
    "cls_list = ['Normal', 'Fall']\n",
    "cls_filename_list = ['N', 'BY', 'FY', 'SY']\n",
    "\n",
    "image_root = f'{train_root}\\\\images'\n",
    "label_root = f'{train_root}\\\\labels'\n",
    "\n",
    "image_list = sorted(glob.glob(f'{image_root}\\\\*.jpg'))\n",
    "print(len(image_list))\n",
    "label_list = [x.replace('images', 'labels').replace('JPG', 'jpg').replace('jpg', 'txt') for x in image_list]\n",
    "print(len(image_list), len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_sampling(image_root, label_root, sample_num):\n",
    "    image_cls_dict = {'N': [], 'BY': [], 'FY': [], 'SY': []}\n",
    "    image_names_dict = {'N': [], 'BY': [], 'FY': [], 'SY': []}\n",
    "    image_sampled_dict = {'N': [], 'BY': [], 'FY': [], 'SY': []}\n",
    "    label_sampled_dict = {'N': [], 'BY': [], 'FY': [], 'SY': []}\n",
    "    for cls in cls_filename_list:\n",
    "        image_cls_dict[cls] = glob.glob(f'{image_root}\\\\*_{cls}_*')\n",
    "        image_names_dict[cls] = list(set([x.split('\\\\')[-1].split('_')[0] for x in image_cls_dict[cls]]))\n",
    "        if cls == 'N':\n",
    "            div = 2\n",
    "        else:\n",
    "            div = 6\n",
    "        image_names_dict[cls] = random.sample(image_names_dict[cls], (sample_num // 80) // div)\n",
    "        for i in tqdm(image_names_dict[cls]):\n",
    "            image_sampled_dict[cls].extend(sorted(glob.glob(f'{image_root}\\\\{i}_*')))\n",
    "            label_sampled_dict[cls].extend(sorted(glob.glob(f'{label_root}\\\\{i}_*')))\n",
    "    print([image_sampled_dict[cls][:10] for cls in cls_filename_list])\n",
    "    print([label_sampled_dict[cls][:10] for cls in cls_filename_list])\n",
    "    print([len(image_sampled_dict[cls]) for cls in cls_filename_list])\n",
    "    return image_sampled_dict, label_sampled_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.77it/s]\n",
      "100%|██████████| 33/33 [00:04<00:00,  6.77it/s]\n",
      "100%|██████████| 33/33 [00:04<00:00,  6.78it/s]\n",
      "100%|██████████| 33/33 [00:04<00:00,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I001.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I002.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I003.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I004.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I005.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I006.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I007.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I008.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I009.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I010.jpg'], ['E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02140_H_A_BY_C1_I001.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02140_H_A_BY_C1_I002.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02140_H_A_BY_C1_I003.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02140_H_A_BY_C1_I004.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02140_H_A_BY_C1_I005.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02140_H_A_BY_C1_I006.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02140_H_A_BY_C1_I007.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02140_H_A_BY_C1_I008.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02140_H_A_BY_C1_I009.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02140_H_A_BY_C1_I010.jpg'], ['E:\\\\project\\\\New_Data\\\\train\\\\images\\\\00483_H_D_FY_C1_I001.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\00483_H_D_FY_C1_I002.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\00483_H_D_FY_C1_I003.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\00483_H_D_FY_C1_I004.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\00483_H_D_FY_C1_I005.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\00483_H_D_FY_C1_I006.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\00483_H_D_FY_C1_I007.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\00483_H_D_FY_C1_I008.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\00483_H_D_FY_C1_I009.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\00483_H_D_FY_C1_I010.jpg'], ['E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02442_H_A_SY_C1_I001.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02442_H_A_SY_C1_I002.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02442_H_A_SY_C1_I003.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02442_H_A_SY_C1_I004.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02442_H_A_SY_C1_I005.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02442_H_A_SY_C1_I006.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02442_H_A_SY_C1_I007.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02442_H_A_SY_C1_I008.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02442_H_A_SY_C1_I009.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02442_H_A_SY_C1_I010.jpg']]\n",
      "[['E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02270_H_A_N_C1_I001.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02270_H_A_N_C1_I002.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02270_H_A_N_C1_I003.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02270_H_A_N_C1_I004.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02270_H_A_N_C1_I005.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02270_H_A_N_C1_I006.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02270_H_A_N_C1_I007.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02270_H_A_N_C1_I008.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02270_H_A_N_C1_I009.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02270_H_A_N_C1_I010.txt'], ['E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02140_H_A_BY_C1_I001.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02140_H_A_BY_C1_I002.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02140_H_A_BY_C1_I003.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02140_H_A_BY_C1_I004.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02140_H_A_BY_C1_I005.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02140_H_A_BY_C1_I006.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02140_H_A_BY_C1_I007.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02140_H_A_BY_C1_I008.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02140_H_A_BY_C1_I009.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02140_H_A_BY_C1_I010.txt'], ['E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\00483_H_D_FY_C1_I001.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\00483_H_D_FY_C1_I002.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\00483_H_D_FY_C1_I003.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\00483_H_D_FY_C1_I004.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\00483_H_D_FY_C1_I005.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\00483_H_D_FY_C1_I006.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\00483_H_D_FY_C1_I007.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\00483_H_D_FY_C1_I008.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\00483_H_D_FY_C1_I009.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\00483_H_D_FY_C1_I010.txt'], ['E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02442_H_A_SY_C1_I001.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02442_H_A_SY_C1_I002.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02442_H_A_SY_C1_I003.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02442_H_A_SY_C1_I004.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02442_H_A_SY_C1_I005.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02442_H_A_SY_C1_I006.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02442_H_A_SY_C1_I007.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02442_H_A_SY_C1_I008.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02442_H_A_SY_C1_I009.txt', 'E:\\\\project\\\\New_Data\\\\train\\\\labels\\\\02442_H_A_SY_C1_I010.txt']]\n",
      "[8000, 2640, 2640, 2640]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원하는 양의 이미지&라벨을 샘플링한 후 각 클래스(N, BY, SY, FY) 형태로 저장\n",
    "image_dict, label_dict = image_sampling(image_root, label_root, 16000)\n",
    "len(label_dict['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCH = 2\n",
    "NUM_LAYERS = 1\n",
    "n_CONFIDENCE = 0.3\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "attention_dot = [n for n in range(29)]\n",
    "\n",
    "\n",
    "draw_line = [[11, 13], [13, 15], [15, 21], [15, 19], [15, 17], [17, 19], [12, 14], [14, 16],\n",
    "             [16, 22], [16, 20], [16, 18], [18, 20], [23, 25], [25, 27], [24, 26], [26, 28],\n",
    "             [11, 12], [11, 23], [23, 24], [12, 24], [9, 10], [0, 5], [0, 2], [5, 8], [2, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose(image_list: list, label_list: list, label_type: str, attention_dot: list, draw_line: list, isSample=False, sample_size=0):\n",
    "    if isSample:\n",
    "        print('sample mod')\n",
    "        print(len(image_list))\n",
    "        plt.figure(figsize=(8, 4*sample_size))\n",
    "    frame_length = 10 # LSTM 모델에 넣을 frame 수\n",
    "    xy_list_list = []\n",
    "    omission_cnt = 0\n",
    "    for i, (img_src, lbl) in enumerate((zip(image_list, label_list))):\n",
    "        if label_type == 'yolo':\n",
    "            with open(lbl, 'r', encoding='utf-8') as f:\n",
    "                label_str = f.read()\n",
    "                bbox = list(map(float, label_str.split(' ')[1:]))\n",
    "\n",
    "            bbox = [int(x * 640) for x in bbox]\n",
    "            bbox = [\n",
    "                max(int(bbox[0] - bbox[2] / 2 - 30), 0),\n",
    "                max(int(bbox[1] - bbox[3] / 2 - 30), 0),\n",
    "                min(int(bbox[0] + bbox[2] / 2 + 30), 640),\n",
    "                min(int(bbox[1] + bbox[3] / 2 + 30), 640),\n",
    "            ]\n",
    "            img = cv2.imread(img_src)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if isSample:\n",
    "                bbox_img = cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 0), 2)\n",
    "                cv2.putText(bbox_img, img_src.split('\\\\')[-1], (5, 30), cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 255, 255), lineType=cv2.LINE_AA)\n",
    "                plt.subplot(sample_size, 2, (2*i+1))\n",
    "                plt.imshow(bbox_img)\n",
    "\n",
    "        \n",
    "        \"\"\" Yolov5 바운딩 박스 좌표 안에서 mediapipe Pose 추출\"\"\"\n",
    "\n",
    "        c_img = img[bbox[1]:bbox[3], bbox[0]:bbox[2]] # 바운딩 박스 좌표/\n",
    "        del img\n",
    "        results = pose.process(c_img) # Yolov5 바운딩 박스 좌표 안에서 'mp_pose' 좌표\n",
    "\n",
    "        if not results.pose_landmarks: continue\n",
    "        idx = 0\n",
    "        draw_line_dic = {}\n",
    "        xy_list = []\n",
    "        # 33 반복문 진행 : 33개 중 18개의 dot\n",
    "        for x_and_y in results.pose_landmarks.landmark:\n",
    "            if idx in attention_dot:\n",
    "                xy_list.append(x_and_y.x)\n",
    "                xy_list.append(x_and_y.y)\n",
    "\n",
    "                x, y = int(x_and_y.x * (bbox[2] - bbox[0])), int(x_and_y.y * (bbox[3] - bbox[1]))\n",
    "                draw_line_dic[idx] = [x, y]\n",
    "            idx += 1\n",
    "\n",
    "        if len(xy_list) != len(attention_dot) * 2:\n",
    "            print('Error : attention_dot 데이터 오류')\n",
    "\n",
    "        xy_list_list.append(xy_list)\n",
    "\n",
    "        \"\"\"mediapipe line 그리기 부분 : 데이터 추출(dot) 확인용\"\"\"\n",
    "        if isSample:\n",
    "            for line in draw_line:\n",
    "                x1, y1 = draw_line_dic[line[0]][0], draw_line_dic[line[0]][1]\n",
    "                x2, y2 = draw_line_dic[line[1]][0], draw_line_dic[line[1]][1]\n",
    "                c_img = cv2.line(c_img, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "            plt.subplot(sample_size, 2, (2*i+2))\n",
    "            plt.imshow(c_img)\n",
    "        del c_img\n",
    "        \n",
    "    # 부족한 프레임 수 맞추기\n",
    "    if isSample:\n",
    "        if len(xy_list_list) < len(image_list) // 2:\n",
    "            return False\n",
    "        elif len(xy_list_list) < len(image_list):\n",
    "            f_ln = len(image_list) - len(xy_list)\n",
    "            for _ in range(f_ln):\n",
    "                xy_list_list.append(xy_list_list[-1])\n",
    "    else:\n",
    "        if len(xy_list_list) < 5:\n",
    "            return False, 5 - len(xy_list_list)\n",
    "        elif len(xy_list_list) < 10:\n",
    "            f_ln = frame_length - len(xy_list)\n",
    "            for _ in range(f_ln):\n",
    "                xy_list_list.append(xy_list_list[-1])\n",
    "                omission_cnt = 1\n",
    "    \n",
    "    if isSample:\n",
    "        plt.show()\n",
    "    return xy_list_list, omission_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터의 일부를 샘플로 잡고, mediapipe로 추출한 pose 데이터를 matplotlib로 plot\n",
    "def get_pose_sample(image_dict: dict, label_dict: dict, label_type: str, attention_dot: list, draw_line: list, sample_size: int, sample_start=0):\n",
    "    image_pose_sample = []\n",
    "    label_pose_sample = []\n",
    "    for cls in cls_filename_list:\n",
    "        div = 2 if cls == 'N' else 6\n",
    "        image_pose_sample.extend(image_dict[cls][sample_start:(sample_start+sample_size//div)])\n",
    "        label_pose_sample.extend(label_dict[cls][sample_start:(sample_start+sample_size//div)])\n",
    "    print(len(image_pose_sample), 'asdf')\n",
    "\n",
    "    xy_sample = get_pose(image_pose_sample, label_pose_sample, label_type, attention_dot, draw_line, True, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m get_pose_sample(image_dict, label_dict, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo\u001b[39m\u001b[38;5;124m'\u001b[39m, attention_dot, draw_line, sample_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# sample\n",
    "get_pose_sample(image_dict, label_dict, 'yolo', attention_dot, draw_line, sample_size=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:00<00:00, 1598972.22it/s]\n",
      "100%|██████████| 2640/2640 [00:00<00:00, 2654750.07it/s]\n",
      "100%|██████████| 2640/2640 [00:00<00:00, 879923.92it/s]\n",
      "100%|██████████| 2640/2640 [00:00<00:00, 1319938.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15920\n",
      "[['E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I001.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I002.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I003.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I004.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I005.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I006.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I007.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I008.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I009.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C1_I010.jpg'], ['E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C2_I001.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C2_I002.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C2_I003.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C2_I004.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C2_I005.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C2_I006.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C2_I007.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C2_I008.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C2_I009.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C2_I010.jpg'], ['E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C3_I001.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C3_I002.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C3_I003.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C3_I004.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C3_I005.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C3_I006.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C3_I007.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C3_I008.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C3_I009.jpg', 'E:\\\\project\\\\New_Data\\\\train\\\\images\\\\02270_H_A_N_C3_I010.jpg']]\n",
      "1588\n",
      "1588\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# [[C1_I0001, C1_I0002, ...C1_I0010], [C2_I0001, ...], ...] 형태로 묶음\n",
    "raw_data = []\n",
    "image_pose_input = []\n",
    "label_pose_input = []\n",
    "for cls in cls_filename_list:\n",
    "    img_name = {'index': 'None', 'direction': 'None'}\n",
    "    img_bundle = []\n",
    "    label_bundle = []\n",
    "    isNewBundle = 0\n",
    "    for img, lbl in zip(tqdm(image_dict[cls]), label_dict[cls]):\n",
    "        # 처음 값 입력\n",
    "        if img_name['index'] != img.split('\\\\')[-1].split('_')[0]:\n",
    "            img_name['index'] = img.split('\\\\')[-1].split('_')[0]\n",
    "            isNewBundle += 1\n",
    "        if img_name['direction'] != img.split('\\\\')[-1].split('_')[-2]:\n",
    "            img_name['direction'] = img.split('\\\\')[-1].split('_')[-2]\n",
    "            isNewBundle += 1\n",
    "        if isNewBundle > 0:\n",
    "            if img_bundle != []:\n",
    "                image_pose_input.append(img_bundle)\n",
    "                label_pose_input.append(label_bundle)\n",
    "            img_bundle = []\n",
    "            label_bundle = []\n",
    "            isNewBundle = 0\n",
    "        img_bundle.append(img)\n",
    "        label_bundle.append(lbl)\n",
    "\n",
    "\n",
    "print(len(image_dict['N'])+len(image_dict['BY'])+len(image_dict['FY'])+len(image_dict['SY']))\n",
    "print(image_pose_input[:3])\n",
    "print(len(image_pose_input))\n",
    "print(len(label_pose_input))\n",
    "\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 414/1588 [03:39<10:22,  1.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_list, lbl_list \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(image_pose_input, label_pose_input):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m img_list[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 5\u001b[0m     pose_list, ommision_cnt \u001b[38;5;241m=\u001b[39m \u001b[43mget_pose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbl_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myolo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_dot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraw_line\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pose_list \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m         raw_data\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: pose_list})\n",
      "Cell \u001b[1;32mIn[10], line 36\u001b[0m, in \u001b[0;36mget_pose\u001b[1;34m(image_list, label_list, label_type, attention_dot, draw_line, isSample, sample_size)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# img = cv2.rectangle(img, start_point, end_point, (0, 0, 255), 2) # 바운딩 박스 그리기 : 데이터 추출 확인용\u001b[39;00m\n\u001b[0;32m     35\u001b[0m c_img \u001b[38;5;241m=\u001b[39m img[bbox[\u001b[38;5;241m1\u001b[39m]:bbox[\u001b[38;5;241m3\u001b[39m], bbox[\u001b[38;5;241m0\u001b[39m]:bbox[\u001b[38;5;241m2\u001b[39m]] \u001b[38;5;66;03m# 바운딩 박스 좌표\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpose\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_img\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Yolov5 바운딩 박스 좌표 안에서 'mp_pose' 좌표\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     39\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001b[0m, in \u001b[0;36mPose.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mediapipe\\python\\solution_base.py:335\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    329\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    331\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    332\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    333\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 335\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolutionOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# mediapipe로 pose data를 list로 추출 후, raw_data에 [{낙상, pose data}, {비낙상, pose data}, ...] 형태로 저장\n",
    "\n",
    "pose = mp_pose.Pose(static_image_mode = True, model_complexity = 1, enable_segmentation = False, min_detection_confidence = n_CONFIDENCE)\n",
    "ommision_total = 0 # 10장의 이미지가 모두 온전히 인식되지 않은 묶음의 개수\n",
    "with tqdm(total=len(image_pose_input)) as pbar:\n",
    "    for img_list, lbl_list in zip(image_pose_input, label_pose_input):\n",
    "        cls = 0 if img_list[0].split('\\\\')[-1].split('_')[-3] == 'N' else 1\n",
    "        pose_list, ommision_cnt = get_pose(img_list, lbl_list, 'yolo', attention_dot, draw_line, False)\n",
    "        if pose_list != False:\n",
    "            raw_data.append({'key': cls, 'value': pose_list})\n",
    "        pbar.update(1)\n",
    "        ommision_total += ommision_cnt\n",
    "\n",
    "print('ommision: ', ommision_total)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_data)\n",
    "nd = 0\n",
    "ad = 0\n",
    "for i in range(len(raw_data)):\n",
    "    if raw_data[i]['key'] == 0:\n",
    "        nd += 1\n",
    "    else:\n",
    "        ad += 1\n",
    "print('normal data:', nd, '| fall data:', ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, seq_list):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for dic in seq_list :\n",
    "            self.y.append(dic['key'])\n",
    "            self.X.append(dic['value'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = [0.8, 0.1, 0.1]\n",
    "train_len = int(len(raw_data) * split_ratio[0])\n",
    "val_len = int(len(raw_data) * split_ratio[1])\n",
    "test_len = len(raw_data) - train_len - val_len\n",
    "\n",
    "print('{}, {}, {}'.format(train_len, val_len, test_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(raw_data)\n",
    "train_data, valid_data, test_data = random_split(train_dataset, [train_len, val_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "class skeleton_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(skeleton_LSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=len(attention_dot) * 2, hidden_size=128, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=128, hidden_size=256, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=256, hidden_size=512, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.lstm4 = nn.LSTM(input_size=512, hidden_size=256, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.lstm5 = nn.LSTM(input_size=256, hidden_size=128, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.lstm6 = nn.LSTM(input_size=128, hidden_size=64, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.lstm7 = nn.LSTM(input_size=64, hidden_size=32, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.fc = nn.Linear(32,2)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x, _ = self.lstm5(x)\n",
    "        x, _ = self.lstm6(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, _ = self.lstm7(x)\n",
    "        x = self.fc(x[:,-1,:]) # x[배치 크기, 시퀀스 길이, 은닉 상태 크기], [:, -1, :] -> 마지막 시간 단계만 선택\n",
    "\n",
    "        return x\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "\n",
    "def init_model():\n",
    "    global net, loss_fn, optim\n",
    "    plt.rc('font', size = 10)\n",
    "    net = skeleton_LSTM().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "# epoch 카운터 초기화\n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "\n",
    "# 모든 Log를 초기화\n",
    "def init_log():\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    plt.rc('font', size = 10)\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    # Train Log 기록\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "\n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    # Validation Log 기록\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "\n",
    "def last(log_list):\n",
    "    # last 안의 마지막 숫자를 반환(print_log 함수에서 사용)\n",
    "    if len(log_list) > 0:\n",
    "        return log_list[len(log_list) - 1]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def print_log():\n",
    "    # 학습 추이 출력 : 소숫점 3자리까지\n",
    "    train_loss = round(float(last(tloss_log)), 3)\n",
    "    train_acc = round(float(last(tacc_log)), 3)\n",
    "    val_loss = round(float(last(vloss_log)), 3)\n",
    "    val_acc = round(float(last(vacc_log)), 3)\n",
    "    time_spent = round(float(last(time_log)), 3)\n",
    "\n",
    "    log_str = 'Epoch: {:3} | T_Loss {:5} | T_Acc {:5} | V_Loss {:5} | V_Acc {:5} | {:5}'.format(last(iter_log), train_loss, train_acc, val_loss, val_acc, time_spent)\n",
    "\n",
    "    log_stack.append(log_str)\n",
    "    \n",
    "    # 학습 추이 그래프 출력\n",
    "    hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99)\n",
    "    hist_fig.patch.set_facecolor('white')\n",
    "\n",
    "    # Loss Line 구성\n",
    "    loss_t_line = plt.plot(iter_log, tloss_log, label='Train_Loss', color='red', marker='o')\n",
    "    loss_v_line = plt.plot(iter_log, vloss_log, label='Valid_Loss', color='blue', marker='s')\n",
    "    loss_axis.set_xlabel('epoch')\n",
    "    loss_axis.set_ylabel('loss')\n",
    "\n",
    "    # Acc, Line 구성\n",
    "    acc_axis = loss_axis.twinx()\n",
    "    acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train_Acc', color='red', marker='+')\n",
    "    acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid_Acc', color='blue', marker='x')\n",
    "    acc_axis.set_ylabel('accuracy')\n",
    "\n",
    "    # 그래프 출력\n",
    "    hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line\n",
    "    loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines])\n",
    "    loss_axis.grid()\n",
    "    plt.title('Learning history until epoch {}'.format(last(iter_log)))\n",
    "    plt.draw()\n",
    "\n",
    "    # 텍스트 로그 출력\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n",
    "    for idx in reversed(range(len(log_stack))):\n",
    "        print(log_stack[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    if device != 'cpu':\n",
    "        empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# 학습 알고리즘\n",
    "def epoch(data_loader, mode = 'train'):\n",
    "    global epoch_cnt\n",
    "\n",
    "    # 사용되는 변수 초기화\n",
    "    iter_loss, iter_acc, last_grad_performed = [], [], False\n",
    "\n",
    "    # 1 iteration 학습 알고리즘(for문을 나오면 1 epoch 완료)\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.type(torch.LongTensor).to(device)\n",
    "\n",
    "        # 1. Feed-forward\n",
    "        if mode == 'train':\n",
    "            net.train()\n",
    "        else:\n",
    "            # 학습때만 쓰이는 Dropout, Batch Mormalization을 미사용\n",
    "            net.eval()\n",
    "\n",
    "        result = net(data) # 1 Batch에 대한 결과가 모든 Class에 대한 확률값으로\n",
    "        _, out = torch.max(result, 1) # result에서 최대 확률값을 기준으로 예측 class 도출( _ : 값 부분은 필요 없음, out : index 중 가장 큰 하나의 데이터)\n",
    "\n",
    "        # 2. Loss 계산\n",
    "        loss = loss_fn(result, label) # GT 와 Label 비교하여 Loss 산정\n",
    "        iter_loss.append(loss.item()) # 학습 추이를 위하여 Loss를 기록\n",
    "\n",
    "        # 3. 역전파 학습 후 Gradient Descent\n",
    "        if mode == 'train':\n",
    "            optim.zero_grad() # 미분을 통해 얻은 기울기를 초기화 for 다음 epoch\n",
    "            loss.backward() # 역전파 학습\n",
    "            optim.step() # Gradient Descent 수행\n",
    "            last_grad_performed = True # for문을 나가면 epoch 카운터 += 1\n",
    "\n",
    "        # 4. 정확도 계산\n",
    "        acc_partial = (out == label).float().sum() # GT == Label 인 개수\n",
    "        acc_partial = acc_partial / len(label) # ( TP / (TP + TM)) 해서 정확도 산출\n",
    "        iter_acc.append(acc_partial.item()) # 학습 추이를 위하여 Acc. 기록\n",
    "\n",
    "    # 역전파 학습 후 Epoch 카운터 += 1\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "\n",
    "    clear_memory()\n",
    "\n",
    "    # loss와 acc의 평균값 for 학습추이 그래프, 모든 GT와 Label 값 for 컨퓨전 매트릭스\n",
    "    return np.average(iter_loss), np.average(iter_acc)\n",
    "\n",
    "def epoch_not_finished():\n",
    "    # 에폭이 끝남을 알림\n",
    "    return epoch_cnt < maximum_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training initialization\n",
    "init_model()\n",
    "init_epoch()\n",
    "init_log()\n",
    "maximum_epoch = EPOCH\n",
    "\n",
    "# Training iteration\n",
    "\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "\n",
    "    tloss, tacc = epoch(train_loader, mode = 'train')\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = epoch(val_loader, mode = 'val')\n",
    "        record_valid_log(vloss, vacc)\n",
    "\n",
    "    print_log()\n",
    "\n",
    "print('\\n Training completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 검증\n",
    "with torch.no_grad():\n",
    "    test_loss, test_acc = epoch(test_loader, mode = 'test')\n",
    "    test_acc = round(test_acc, 4)\n",
    "    test_loss = round(test_loss, 4)\n",
    "    print('Test Acc.: {}'.format(test_acc))\n",
    "    print('Test Loss: {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상 resize 및 추출\n",
    "test_video_name = 'C_3_12_43_BU_SMC_10-14_12-17-14_CC_RGB_DF2_F2'\n",
    "test_video_path = f'/content/drive/MyDrive/Colab_Notebooks/Anomaly Detection/{test_video_name}.mp4'\n",
    "cv2.destroyAllWindows()\n",
    "cap = cv2.VideoCapture(test_video_path)\n",
    "img_list = []\n",
    "\n",
    "if cap.isOpened():\n",
    "\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if ret:\n",
    "            img = cv2.resize(img, (640, 640))\n",
    "            img_list.append(img)\n",
    "            # cv2_imshow(img)\n",
    "            # cv2.waitKey(1)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('저장된 frame의 개수: {}'.format(len(img_list)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
